model_name: LinMulT

# input-output params
input_feature_dim:
  - 768 # wavlm_baseplus
  - 1024 # clip
  - 768 # xlm_roberta

output_dim:
  - 1 # sentiment [-3,+3]
  - 3 # sentiment_class (neutral, positive, negative)

# input handlers
#special_handling:
#  wavlm_baseplus:
#    type: weighted_sum
#    start_layer: 6
#    end_layer: 12

# CM and SA transformer params
d_model: 40
n_heads: 8
n_layers: 6
attention_type: linear # linear, bigbird, softmax, mha

## bigbird attention params - ignored otherwise
#block_size: 64
#num_global_tokens: 16
#num_random_tokens: 10
#dropout_attention: 0.

dropout_embedding: 0
dropout_relu: 0.1
dropout_residual: 0.1
dropout_output: 0

# architecture params
multimodal_signal: True
time_dim_aligner: aap
aligned_time_dim: 300
tam_fusion: True

# task-specific output heads
heads:
  - type: sequence_aggregation
    norm: bn
    pooling: gap
    hidden_dim: 256
    dropout: 0.1
    output_dim: 1 # sentiment [-3,+3]
  - type: sequence_aggregation
    norm: bn
    pooling: gap
    hidden_dim: 256
    dropout: 0.1
    output_dim: 3 # sentiment_class (neutral, positive, negative)